{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Test the exact path our code will use\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "work_folder = os.path.join(desktop_path, \"Facial Deviation Work\")\n",
    "\n",
    "print(f\"Target folder: {work_folder}\")\n",
    "print(f\"Desktop exists: {os.path.exists(desktop_path)}\")\n",
    "print(f\"Desktop writable: {os.access(desktop_path, os.W_OK)}\")\n",
    "\n",
    "try:\n",
    "    os.makedirs(work_folder, exist_ok=True)\n",
    "    test_file = os.path.join(work_folder, \"test.txt\")\n",
    "    with open(test_file, 'w') as f:\n",
    "        f.write(\"test\")\n",
    "    os.remove(test_file)\n",
    "    print(\"Success! Can create folder and files\")\n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd64c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import math\n",
    "import json\n",
    "\n",
    "class RealTimeFacialDeviationTracker:\n",
    "    def __init__(self, openface_path=\"/Users/alibekdadajonov/openface_install/external_libs/openFace/OpenFace\"):\n",
    "        \"\"\"\n",
    "        Initialize the Real-Time Facial Deviation Tracking System with OpenFace UI Features\n",
    "        Based on: Research paper from Frontiers in Psychology (2020)\n",
    "        Using RMSD Formula: sqrt(Σ(d(pf, pf+a)²) / N) where N = 68 facial landmarks\n",
    "        \"\"\"\n",
    "        print(\"OpenFace Real-Time Facial Deviation Tracking System (RMSD-Based)\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Based on: Frontiers in Psychology Research Paper (2020)\")\n",
    "        print(\"RMSD Formula: sqrt(Σ(d(pf, pf+a)²) / N)\")\n",
    "        print(\"Where d(pf, pf+a) = sqrt((x_pf+a - x_pf)² + (y_pf+a - y_pf)²)\")\n",
    "        print(\"Features: 3D Head Pose Cube + Eye Gaze Tracking + Normalized RMSD + DEBUG MODE\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        self.openface_path = openface_path\n",
    "        self.feature_extraction = os.path.join(openface_path, \"build\", \"bin\", \"FeatureExtraction\")\n",
    "        if not os.path.exists(self.feature_extraction):\n",
    "            self.feature_extraction = os.path.join(openface_path, \"exe\", \"FeatureExtraction\")\n",
    "        \n",
    "        self.baseline_landmarks = None\n",
    "        self.baseline_face_stats = None\n",
    "        self.baseline_normalized_landmarks = None  # NEW: Store normalized baseline\n",
    "        self.deviation_data = []\n",
    "        self.detailed_calculations = []\n",
    "        self.accumulated_rmsd = 0.0\n",
    "        self.frame_count = 0\n",
    "        self.debug_mode = True\n",
    "        \n",
    "        # Use system temp directory instead of creating our own\n",
    "        self.temp_dir = tempfile.mkdtemp(prefix=\"openface_\")\n",
    "        print(f\"Using temporary directory: {self.temp_dir}\")\n",
    "\n",
    "    def normalize_landmarks_to_face_size(self, landmarks):\n",
    "        \"\"\"\n",
    "        Normalize landmarks relative to face bounding box to handle position/scale variations\n",
    "        This is the KEY FIX for the coordinate system issues\n",
    "        \"\"\"\n",
    "        if landmarks is None or len(landmarks) == 0:\n",
    "            return None\n",
    "            \n",
    "        # Calculate face bounding box\n",
    "        x_coords = landmarks[:, 0]\n",
    "        y_coords = landmarks[:, 1]\n",
    "        \n",
    "        face_left = np.min(x_coords)\n",
    "        face_right = np.max(x_coords)\n",
    "        face_top = np.min(y_coords)\n",
    "        face_bottom = np.max(y_coords)\n",
    "        \n",
    "        face_width = face_right - face_left\n",
    "        face_height = face_bottom - face_top\n",
    "        face_center_x = (face_left + face_right) / 2\n",
    "        face_center_y = (face_top + face_bottom) / 2\n",
    "        \n",
    "        # Normalize to unit coordinate system (0-1 range)\n",
    "        normalized_landmarks = np.zeros_like(landmarks)\n",
    "        \n",
    "        if face_width > 0 and face_height > 0:\n",
    "            # Center landmarks around face center, then normalize by face dimensions\n",
    "            normalized_landmarks[:, 0] = (landmarks[:, 0] - face_center_x) / face_width\n",
    "            normalized_landmarks[:, 1] = (landmarks[:, 1] - face_center_y) / face_height\n",
    "        \n",
    "        return normalized_landmarks\n",
    "\n",
    "    def setup_baseline(self, num_frames=30):\n",
    "        \"\"\"Capture baseline neutral expression with proper normalization\"\"\"\n",
    "        print(f\"\\n✓ Setting up baseline from {num_frames} frames...\")\n",
    "        print(\"Please maintain a neutral expression and stay in the same position\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(\"Could not open webcam\")\n",
    "        \n",
    "        # Set consistent camera parameters\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "        baseline_landmarks_list = []\n",
    "        baseline_normalized_list = []\n",
    "        baseline_face_stats_list = []\n",
    "        \n",
    "        for i in range(num_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "                \n",
    "            # Save frame temporarily\n",
    "            temp_image = os.path.join(self.temp_dir, f\"baseline_{i}.jpg\")\n",
    "            cv2.imwrite(temp_image, frame)\n",
    "            \n",
    "            # Process with OpenFace\n",
    "            face_data = self.extract_landmarks_from_image(temp_image)\n",
    "            if face_data is not None and 'landmarks_2d' in face_data:\n",
    "                landmarks = face_data['landmarks_2d']\n",
    "                \n",
    "                # Store both raw and normalized landmarks\n",
    "                baseline_landmarks_list.append(landmarks)\n",
    "                \n",
    "                # Normalize landmarks for consistent comparison\n",
    "                normalized_landmarks = self.normalize_landmarks_to_face_size(landmarks)\n",
    "                if normalized_landmarks is not None:\n",
    "                    baseline_normalized_list.append(normalized_landmarks)\n",
    "                \n",
    "                # Collect face statistics\n",
    "                face_stats = self.check_face_consistency(landmarks)\n",
    "                if face_stats:\n",
    "                    baseline_face_stats_list.append(face_stats)\n",
    "                \n",
    "                print(f\"✓ Baseline frame {i+1}/{num_frames} processed\")\n",
    "            \n",
    "            # Show preview\n",
    "            cv2.putText(frame, f\"Baseline Setup: {i+1}/{num_frames}\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Keep still and maintain neutral expression\", (10, 60),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "            cv2.imshow('Baseline Setup', frame)\n",
    "            cv2.waitKey(100)\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        if len(baseline_landmarks_list) > 0 and len(baseline_normalized_list) > 0:\n",
    "            # Calculate average baseline (both raw and normalized)\n",
    "            self.baseline_landmarks = np.mean(baseline_landmarks_list, axis=0)\n",
    "            self.baseline_normalized_landmarks = np.mean(baseline_normalized_list, axis=0)\n",
    "            \n",
    "            # Calculate average baseline face statistics\n",
    "            if baseline_face_stats_list:\n",
    "                avg_width = np.mean([stats[0] for stats in baseline_face_stats_list])\n",
    "                avg_height = np.mean([stats[1] for stats in baseline_face_stats_list])\n",
    "                avg_center = np.mean([stats[2] for stats in baseline_face_stats_list], axis=0)\n",
    "                self.baseline_face_stats = (avg_width, avg_height, avg_center)\n",
    "            \n",
    "            print(f\"✓ Baseline established from {len(baseline_landmarks_list)} frames\")\n",
    "            print(f\"Raw baseline shape: {self.baseline_landmarks.shape}\")\n",
    "            print(f\"Normalized baseline shape: {self.baseline_normalized_landmarks.shape}\")\n",
    "            \n",
    "            # Debug baseline statistics\n",
    "            if self.baseline_face_stats:\n",
    "                print(f\"Baseline face - Width: {self.baseline_face_stats[0]:.1f}, \"\n",
    "                      f\"Height: {self.baseline_face_stats[1]:.1f}, \"\n",
    "                      f\"Center: ({self.baseline_face_stats[2][0]:.1f},{self.baseline_face_stats[2][1]:.1f})\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\" Failed to establish baseline - no faces detected\")\n",
    "            return False\n",
    "\n",
    "    def calculate_rmsd_deviation_detailed(self, current_data):\n",
    "        \"\"\"Calculate RMSD deviation using NORMALIZED landmarks - KEY FIX\"\"\"\n",
    "        if self.baseline_normalized_landmarks is None or current_data is None:\n",
    "            return 0.0, [], {}\n",
    "        \n",
    "        current_landmarks = current_data.get('landmarks_2d')\n",
    "        if current_landmarks is None:\n",
    "            return 0.0, [], {}\n",
    "        \n",
    "        # NORMALIZE current landmarks to handle position/scale differences\n",
    "        current_normalized = self.normalize_landmarks_to_face_size(current_landmarks)\n",
    "        if current_normalized is None:\n",
    "            return 0.0, [], {}\n",
    "        \n",
    "        # Ensure shapes match\n",
    "        if current_normalized.shape != self.baseline_normalized_landmarks.shape:\n",
    "            print(f\"  SHAPE MISMATCH: Baseline {self.baseline_normalized_landmarks.shape} vs Current {current_normalized.shape}\")\n",
    "            return 0.0, [], {}\n",
    "        \n",
    "        # Detailed calculation tracking\n",
    "        detailed_calc = {\n",
    "            'frame_number': self.frame_count,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'normalization_applied': True,  # NEW: Track that normalization was used\n",
    "            'formula_explanation': {\n",
    "                'step1': 'Normalize landmarks to face-relative coordinates (0-1 range)',\n",
    "                'step2': 'Calculate Euclidean distance for each normalized landmark: d(pf, pf+a) = sqrt((x_pf+a - x_pf)² + (y_pf+a - y_pf)²)',\n",
    "                'step3': 'Square each distance: d²',\n",
    "                'step4': 'Sum all squared distances: Σ(d²)',\n",
    "                'step5': 'Divide by number of landmarks (N=68): Σ(d²)/N',\n",
    "                'step6': 'Take square root for final RMSD: sqrt(Σ(d²)/N)'\n",
    "            },\n",
    "            'landmark_calculations': [],\n",
    "            'intermediate_values': {}\n",
    "        }\n",
    "        \n",
    "        # Calculate distances using NORMALIZED coordinates\n",
    "        landmark_distances = []\n",
    "        sum_squared_distances = 0.0\n",
    "        \n",
    "        for i in range(len(current_normalized)):\n",
    "            baseline_point = self.baseline_normalized_landmarks[i]\n",
    "            current_point = current_normalized[i]\n",
    "            \n",
    "            x_diff = current_point[0] - baseline_point[0]\n",
    "            y_diff = current_point[1] - baseline_point[1]\n",
    "            distance_squared = x_diff ** 2 + y_diff ** 2\n",
    "            distance = np.sqrt(distance_squared)\n",
    "            \n",
    "            landmark_distances.append(distance)\n",
    "            sum_squared_distances += distance_squared\n",
    "            \n",
    "            # Store detailed calculation for first 10 landmarks\n",
    "            if i < 10:\n",
    "                detailed_calc['landmark_calculations'].append({\n",
    "                    'landmark_index': i,\n",
    "                    'baseline_normalized': [float(baseline_point[0]), float(baseline_point[1])],\n",
    "                    'current_normalized': [float(current_point[0]), float(current_point[1])],\n",
    "                    'x_difference': float(x_diff),\n",
    "                    'y_difference': float(y_diff),\n",
    "                    'distance_squared': float(distance_squared),\n",
    "                    'euclidean_distance': float(distance)\n",
    "                })\n",
    "        \n",
    "        landmark_distances = np.array(landmark_distances)\n",
    "        \n",
    "        # Calculate RMSD\n",
    "        N = len(landmark_distances)\n",
    "        mean_squared_distance = sum_squared_distances / N\n",
    "        rmsd = np.sqrt(mean_squared_distance)\n",
    "        \n",
    "        # Store intermediate values\n",
    "        detailed_calc['intermediate_values'] = {\n",
    "            'N_landmarks': N,\n",
    "            'sum_squared_distances': float(sum_squared_distances),\n",
    "            'mean_squared_distance': float(mean_squared_distance),\n",
    "            'rmsd_final': float(rmsd)\n",
    "        }\n",
    "        \n",
    "        # Add statistics\n",
    "        detailed_calc['landmark_statistics'] = {\n",
    "            'min_distance': float(np.min(landmark_distances)),\n",
    "            'max_distance': float(np.max(landmark_distances)),\n",
    "            'mean_distance': float(np.mean(landmark_distances)),\n",
    "            'std_distance': float(np.std(landmark_distances)),\n",
    "            'median_distance': float(np.median(landmark_distances))\n",
    "        }\n",
    "        \n",
    "        return float(rmsd), landmark_distances.tolist(), detailed_calc\n",
    "\n",
    "    def debug_landmark_distances(self, current_data):\n",
    "        \"\"\"Enhanced debug method using normalized coordinates\"\"\"\n",
    "        if self.baseline_normalized_landmarks is None or current_data is None:\n",
    "            return\n",
    "        \n",
    "        current_landmarks = current_data.get('landmarks_2d')\n",
    "        if current_landmarks is None:\n",
    "            return\n",
    "        \n",
    "        current_normalized = self.normalize_landmarks_to_face_size(current_landmarks)\n",
    "        if current_normalized is None:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== DEBUGGING FRAME {self.frame_count} (NORMALIZED COORDINATES) ===\")\n",
    "        print(f\"Baseline normalized shape: {self.baseline_normalized_landmarks.shape}\")\n",
    "        print(f\"Current normalized shape: {current_normalized.shape}\")\n",
    "        \n",
    "        # Check face consistency (raw coordinates)\n",
    "        current_face_stats = self.check_face_consistency(current_landmarks)\n",
    "        if current_face_stats and self.baseline_face_stats:\n",
    "            print(f\"Raw baseline face - W:{self.baseline_face_stats[0]:.1f} H:{self.baseline_face_stats[1]:.1f}\")\n",
    "            print(f\"Raw current face  - W:{current_face_stats[0]:.1f} H:{current_face_stats[1]:.1f}\")\n",
    "            \n",
    "            # Check for significant face size changes\n",
    "            width_change = abs(current_face_stats[0] - self.baseline_face_stats[0]) / self.baseline_face_stats[0] * 100\n",
    "            height_change = abs(current_face_stats[1] - self.baseline_face_stats[1]) / self.baseline_face_stats[1] * 100\n",
    "            \n",
    "            if width_change > 20 or height_change > 20:\n",
    "                print(f\"  RAW FACE SIZE MISMATCH: Width change {width_change:.1f}%, Height change {height_change:.1f}%\")\n",
    "            else:\n",
    "                print(f\" Face size consistent: Width change {width_change:.1f}%, Height change {height_change:.1f}%\")\n",
    "        \n",
    "        # Check normalized coordinates (should be much more consistent)\n",
    "        print(f\"\\nNORMALIZED COORDINATE ANALYSIS:\")\n",
    "        \n",
    "        # Check first 5 landmarks in detail\n",
    "        for i in range(min(5, len(current_normalized))):\n",
    "            baseline_point = self.baseline_normalized_landmarks[i]\n",
    "            current_point = current_normalized[i]\n",
    "            \n",
    "            x_diff = current_point[0] - baseline_point[0]\n",
    "            y_diff = current_point[1] - baseline_point[1]\n",
    "            distance = np.sqrt(x_diff**2 + y_diff**2)\n",
    "            \n",
    "            print(f\"Landmark {i:2d}: Base({baseline_point[0]:6.3f},{baseline_point[1]:6.3f}) \"\n",
    "                  f\"Curr({current_point[0]:6.3f},{current_point[1]:6.3f}) \"\n",
    "                  f\"Diff({x_diff:6.3f},{y_diff:6.3f}) Dist={distance:.3f}\")\n",
    "        \n",
    "        # Overall normalized statistics\n",
    "        all_distances = []\n",
    "        for i in range(len(current_normalized)):\n",
    "            baseline_point = self.baseline_normalized_landmarks[i]\n",
    "            current_point = current_normalized[i]\n",
    "            distance = np.sqrt((current_point[0] - baseline_point[0])**2 +\n",
    "                             (current_point[1] - baseline_point[1])**2)\n",
    "            all_distances.append(distance)\n",
    "        \n",
    "        print(f\"Normalized distance stats - Min: {np.min(all_distances):.4f}, \"\n",
    "              f\"Max: {np.max(all_distances):.4f}, \"\n",
    "              f\"Mean: {np.mean(all_distances):.4f}, \"\n",
    "              f\"Median: {np.median(all_distances):.4f}\")\n",
    "        \n",
    "        # Flag if still getting extreme values in normalized space\n",
    "        if np.mean(all_distances) > 0.1:  # 0.1 is 10% of face in normalized space\n",
    "            print(f\"  HIGH NORMALIZED DISTANCES - May indicate expression change or detection error\")\n",
    "        else:\n",
    "            print(f\" Normalized distances look reasonable\")\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "\n",
    "    def debug_baseline_vs_current(self, current_data, frame):\n",
    "        \"\"\"Debug visualization using both raw and normalized coordinates\"\"\"\n",
    "        if self.baseline_landmarks is None or current_data is None:\n",
    "            return frame\n",
    "        \n",
    "        current_landmarks = current_data.get('landmarks_2d')\n",
    "        if current_landmarks is None:\n",
    "            return frame\n",
    "        \n",
    "        # Only show debug visualization if debug_mode is on\n",
    "        if not self.debug_mode:\n",
    "            return frame\n",
    "        \n",
    "        # Draw baseline landmarks in blue (smaller circles)\n",
    "        for i, point in enumerate(self.baseline_landmarks):\n",
    "            x, y = int(point[0]), int(point[1])\n",
    "            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:\n",
    "                cv2.circle(frame, (x, y), 1, (255, 0, 0), -1)  # Blue for baseline\n",
    "        \n",
    "        # Draw current landmarks in red\n",
    "        for i, point in enumerate(current_landmarks):\n",
    "            x, y = int(point[0]), int(point[1])\n",
    "            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:\n",
    "                cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)  # Red for current\n",
    "                \n",
    "                # Draw line connecting baseline to current for high deviation landmarks\n",
    "                baseline_point = self.baseline_landmarks[i]\n",
    "                bx, by = int(baseline_point[0]), int(baseline_point[1])\n",
    "                raw_distance = np.sqrt((x - bx)**2 + (y - by)**2)\n",
    "                \n",
    "                # Only draw connection lines for high deviation points in raw space\n",
    "                if raw_distance > 10:  # Show connections for points that moved >10 pixels\n",
    "                    cv2.line(frame, (bx, by), (x, y), (0, 255, 0), 1)  # Green connecting line\n",
    "        \n",
    "        # Add debug info with normalized distance information\n",
    "        cv2.putText(frame, \"DEBUG: Blue=Baseline, Red=Current, Green=High Raw Deviation\",\n",
    "                   (10, frame.shape[0] - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"RMSD calculated using NORMALIZED coordinates\",\n",
    "                   (10, frame.shape[0] - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def start_tracking(self, duration_minutes=None, jupyter_mode=False):\n",
    "        \"\"\"Start real-time tracking - asks user for duration or runs until 'q' is pressed\"\"\"\n",
    "        if self.baseline_normalized_landmarks is None:\n",
    "            print(\" Baseline not established. Run setup_baseline() first.\")\n",
    "            return\n",
    "        \n",
    "        # Handle user input for tracking duration\n",
    "        if duration_minutes is None and not jupyter_mode:\n",
    "            print(\"\\n Starting real-time RMSD tracking...\")\n",
    "            while True:\n",
    "                try:\n",
    "                    user_input = input(\"Enter tracking duration in minutes (or press Enter for unlimited): \").strip()\n",
    "                    if user_input == \"\":\n",
    "                        duration_minutes = None\n",
    "                        print(\" Unlimited tracking mode - press 'q' to quit anytime\")\n",
    "                        break\n",
    "                    else:\n",
    "                        duration_minutes = float(user_input)\n",
    "                        if duration_minutes > 0:\n",
    "                            print(f\" Tracking for {duration_minutes} minutes (press 'q' to quit early)\")\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"Please enter a positive number\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number or press Enter for unlimited\")\n",
    "        elif duration_minutes is None and jupyter_mode:\n",
    "            print(\"\\n Jupyter mode: Running unlimited tracking - press 'q' to quit\")\n",
    "            duration_minutes = None\n",
    "        elif duration_minutes is not None:\n",
    "            print(f\"\\n Starting {duration_minutes}-minute tracking session\")\n",
    "        \n",
    "        print(\" Using NORMALIZED coordinates to handle position/scale variations\")\n",
    "        print(\"DEBUG MODE ENABLED - Extra diagnostic information will be shown\")\n",
    "        print(\"Press 'q' to quit, 's' to save data, 'd' to toggle debug mode\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(\"Could not open webcam\")\n",
    "        \n",
    "        # Set same camera parameters as baseline\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        end_time = start_time + (duration_minutes * 60) if duration_minutes else None\n",
    "        \n",
    "        while True:\n",
    "            # Check if duration limit reached (only if duration_minutes is specified)\n",
    "            if end_time and time.time() >= end_time:\n",
    "                print(f\"\\n Time limit of {duration_minutes} minutes reached\")\n",
    "                break\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            temp_image = os.path.join(self.temp_dir, f\"frame_{self.frame_count}.jpg\")\n",
    "            cv2.imwrite(temp_image, frame)\n",
    "            \n",
    "            current_data = self.extract_landmarks_from_image(temp_image)\n",
    "            \n",
    "            if current_data is not None:\n",
    "                # Debug output for first 3 frames\n",
    "                if self.frame_count < 3 and self.debug_mode:\n",
    "                    self.debug_landmark_distances(current_data)\n",
    "                \n",
    "                # Calculate RMSD with normalization\n",
    "                rmsd_deviation, landmark_distances, detailed_calc = self.calculate_rmsd_deviation_detailed(current_data)\n",
    "                self.accumulated_rmsd += rmsd_deviation\n",
    "                \n",
    "                self.detailed_calculations.append(detailed_calc)\n",
    "                \n",
    "                # Store data\n",
    "                timestamp = datetime.now()\n",
    "                self.deviation_data.append({\n",
    "                    'timestamp': timestamp.isoformat(),\n",
    "                    'frame': self.frame_count,\n",
    "                    'rmsd_deviation': float(rmsd_deviation),\n",
    "                    'accumulated_rmsd': float(self.accumulated_rmsd),\n",
    "                    'avg_rmsd': float(self.accumulated_rmsd / (self.frame_count + 1)),\n",
    "                    'max_landmark_deviation': float(max(landmark_distances)) if landmark_distances else 0.0,\n",
    "                    'min_landmark_deviation': float(min(landmark_distances)) if landmark_distances else 0.0,\n",
    "                    'std_landmark_deviation': float(np.std(landmark_distances)) if landmark_distances else 0.0,\n",
    "                    'normalization_used': True  # Track that normalization was applied\n",
    "                })\n",
    "                \n",
    "                # Add debug visualization\n",
    "                if self.debug_mode:\n",
    "                    frame = self.debug_baseline_vs_current(current_data, frame)\n",
    "                \n",
    "                # Get visualization data\n",
    "                landmarks_2d = current_data.get('landmarks_2d')\n",
    "                head_pose = current_data.get('head_pose')\n",
    "                left_eye = current_data.get('left_eye')\n",
    "                right_eye = current_data.get('right_eye')\n",
    "                gaze = current_data.get('gaze')\n",
    "                \n",
    "                if landmarks_2d is not None:\n",
    "                    face_center = np.mean(landmarks_2d, axis=0)\n",
    "                    \n",
    "                    # Draw visualizations (only if not in debug mode to avoid clutter)\n",
    "                    if not self.debug_mode:\n",
    "                        if head_pose is not None:\n",
    "                            frame = self.draw_openface_3d_cube(frame, head_pose, face_center)\n",
    "                        frame = self.draw_landmark_deviation_visualization(frame, landmarks_2d, landmark_distances)\n",
    "                        frame = self.draw_openface_landmarks_and_gaze(frame, landmarks_2d, left_eye, right_eye, gaze)\n",
    "                \n",
    "                # Display tracking information with improved color coding\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                # Calculate remaining time only if duration is set\n",
    "                if end_time:\n",
    "                    remaining = max(0, end_time - time.time())\n",
    "                    time_display = f\"Time: {int(elapsed)}s / {int(remaining)}s left\"\n",
    "                else:\n",
    "                    hours = int(elapsed // 3600)\n",
    "                    minutes = int((elapsed % 3600) // 60)\n",
    "                    seconds = int(elapsed % 60)\n",
    "                    if hours > 0:\n",
    "                        time_display = f\"Time: {hours}h {minutes}m {seconds}s\"\n",
    "                    elif minutes > 0:\n",
    "                        time_display = f\"Time: {minutes}m {seconds}s\"\n",
    "                    else:\n",
    "                        time_display = f\"Time: {seconds}s\"\n",
    "                \n",
    "                # Info panel with subtle background and border\n",
    "                panel_height = 320 if self.debug_mode else 270\n",
    "                cv2.rectangle(frame, (10, 10), (550, panel_height), (40, 40, 40), -1)  # Dark background\n",
    "                cv2.rectangle(frame, (10, 10), (550, panel_height), (100, 150, 200), 2)  # Blue border\n",
    "                \n",
    "                # Header section\n",
    "                cv2.rectangle(frame, (15, 15), (545, 45), (60, 60, 60), -1)  # Header background\n",
    "                cv2.putText(frame, \"REAL-TIME FACIAL DEVIATION ANALYSIS\", (20, 35),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # RMSD section with color-coded background\n",
    "                rmsd_bg_color = (0, 80, 0) if rmsd_deviation < 0.01 else (0, 60, 80) if rmsd_deviation < 0.05 else (0, 0, 80)\n",
    "                cv2.rectangle(frame, (15, 50), (545, 125), rmsd_bg_color, -1)  # RMSD section background\n",
    "                \n",
    "                # RMSD info with realistic color coding for normalized values\n",
    "                if rmsd_deviation < 0.01:\n",
    "                    rmsd_color = (100, 255, 100)    # Light green - very small deviation\n",
    "                    status_text = \"NORMAL\"\n",
    "                    status_color = (100, 255, 100)\n",
    "                elif rmsd_deviation < 0.05:\n",
    "                    rmsd_color = (0, 200, 255)      # Light orange - moderate deviation\n",
    "                    status_text = \"ELEVATED\"\n",
    "                    status_color = (0, 200, 255)\n",
    "                else:\n",
    "                    rmsd_color = (100, 100, 255)    # Light red - high deviation\n",
    "                    status_text = \"HIGH\"\n",
    "                    status_color = (100, 100, 255)\n",
    "                \n",
    "                cv2.putText(frame, f\"Normalized RMSD: {rmsd_deviation:.6f}\", (20, 70),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, rmsd_color, 2)\n",
    "                cv2.putText(frame, f\"Accumulated RMSD: {self.accumulated_rmsd:.6f}\", (20, 90),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "                cv2.putText(frame, f\"Average RMSD: {self.accumulated_rmsd / (self.frame_count + 1):.6f}\", (20, 110),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "                \n",
    "                # Status indicator with background\n",
    "                cv2.rectangle(frame, (350, 55), (540, 85), (80, 80, 80), -1)  # Status background\n",
    "                cv2.putText(frame, f\"Status: {status_text}\", (355, 75),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)\n",
    "                \n",
    "                # Statistics section\n",
    "                cv2.rectangle(frame, (15, 130), (545, 190), (50, 50, 50), -1)  # Stats background\n",
    "                cv2.putText(frame, f\"Max Normalized Dev: {max(landmark_distances) if landmark_distances else 0:.4f}\", (20, 150),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 255, 255), 1)\n",
    "                cv2.putText(frame, time_display, (20, 170),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (150, 255, 150), 2)\n",
    "                cv2.putText(frame, f\"Frames Processed: {len(self.deviation_data)}\", (280, 170),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 255, 150), 1)\n",
    "                \n",
    "                # Head pose section\n",
    "                if head_pose is not None and len(head_pose) > 0:\n",
    "                    cv2.rectangle(frame, (15, 195), (545, 235), (60, 40, 60), -1)  # Pose background\n",
    "                    pitch, yaw, roll = head_pose * 180 / np.pi\n",
    "                    cv2.putText(frame, f\"Head Pose - Pitch: {pitch:.1f}deg\", (20, 215),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 180, 100), 1)\n",
    "                    cv2.putText(frame, f\"Yaw: {yaw:.1f}deg  Roll: {roll:.1f}deg\", (20, 230),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 180, 100), 1)\n",
    "                    controls_y = 245\n",
    "                else:\n",
    "                    controls_y = 200\n",
    "                \n",
    "                # Control indicators section\n",
    "                cv2.rectangle(frame, (15, controls_y), (545, controls_y + 60), (40, 60, 40), -1)  # Controls background\n",
    "                cv2.putText(frame, \"NORMALIZATION ACTIVE\", (20, controls_y + 20),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 100), 1)\n",
    "                \n",
    "                # Control instructions\n",
    "                cv2.putText(frame, \"Controls: Q=Quit | S=Save | D=Debug Toggle\", (20, controls_y + 40),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 100), 1)\n",
    "                \n",
    "                # Debug mode indicator\n",
    "                if self.debug_mode:\n",
    "                    cv2.putText(frame, \"DEBUG MODE ACTIVE\", (20, controls_y + 55),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 255, 255), 1)\n",
    "                \n",
    "            else:\n",
    "                # No face detected\n",
    "                cv2.rectangle(frame, (10, 10), (300, 80), (0, 0, 0), -1)\n",
    "                cv2.putText(frame, \"No face detected\", (15, 35),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Ensure good lighting and face camera\", (15, 60),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            \n",
    "            cv2.putText(frame, \"OpenFace RMSD Tracking (Normalized Coordinates)\", (10, frame.shape[0] - 20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('OpenFace RMSD Facial Deviation Tracking', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                print(\"\\n Tracking stopped by user\")\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                csv_file, report_file = self.save_all_data()\n",
    "                print(f\" Data saved! CSV: {csv_file}, Report: {report_file}\")\n",
    "            elif key == ord('d'):\n",
    "                self.debug_mode = not self.debug_mode\n",
    "                print(f\" Debug mode: {'ON' if self.debug_mode else 'OFF'}\")\n",
    "            \n",
    "            self.frame_count += 1\n",
    "            \n",
    "            # Clean up frame file\n",
    "            if os.path.exists(temp_image):\n",
    "                os.remove(temp_image)\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        print(f\"\\n Tracking completed! Processed {len(self.deviation_data)} frames\")\n",
    "        return self.save_all_data()\n",
    "\n",
    "    def extract_landmarks_from_image(self, image_path):\n",
    "        \"\"\"Extract facial landmarks and pose data from a single image using OpenFace\"\"\"\n",
    "        try:\n",
    "            output_dir = os.path.join(self.temp_dir, f\"output_{int(time.time() * 1000)}\")\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            cmd = [\n",
    "                self.feature_extraction,\n",
    "                \"-f\", image_path,\n",
    "                \"-out_dir\", output_dir,\n",
    "                \"-2Dfp\", \"-3Dfp\", \"-pdmparams\", \"-pose\", \"-gaze\", \"-aus\",\n",
    "                \"-quiet\"\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                print(f\"OpenFace error: {result.stderr}\")\n",
    "                return None\n",
    "            \n",
    "            csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]\n",
    "            if not csv_files:\n",
    "                return None\n",
    "            \n",
    "            csv_path = os.path.join(output_dir, csv_files[0])\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(csv_path, engine='python')\n",
    "            except:\n",
    "                with open(csv_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    if len(lines) < 2:\n",
    "                        return None\n",
    "                    \n",
    "                    headers = lines[0].strip().split(',')\n",
    "                    values = lines[1].strip().split(',')\n",
    "                    \n",
    "                    data_dict = {}\n",
    "                    for i, header in enumerate(headers):\n",
    "                        if i < len(values):\n",
    "                            try:\n",
    "                                data_dict[header] = float(values[i])\n",
    "                            except ValueError:\n",
    "                                data_dict[header] = values[i]\n",
    "                    \n",
    "                    df = pd.DataFrame([data_dict])\n",
    "            \n",
    "            data = {}\n",
    "            \n",
    "            # Extract 2D landmarks\n",
    "            landmark_cols = []\n",
    "            for i in range(68):\n",
    "                x_col = f'x_{i}'\n",
    "                y_col = f'y_{i}'\n",
    "                if x_col in df.columns and y_col in df.columns:\n",
    "                    landmark_cols.extend([x_col, y_col])\n",
    "            \n",
    "            if landmark_cols:\n",
    "                landmarks = df[landmark_cols].iloc[0].values\n",
    "                data['landmarks_2d'] = landmarks.reshape(-1, 2)\n",
    "            \n",
    "            # Extract head pose (pitch, yaw, roll)\n",
    "            pose_cols = ['pose_Rx', 'pose_Ry', 'pose_Rz']\n",
    "            if all(col in df.columns for col in pose_cols):\n",
    "                data['head_pose'] = df[pose_cols].iloc[0].values\n",
    "            \n",
    "            # Extract gaze direction\n",
    "            gaze_cols = ['gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z']\n",
    "            available_gaze_cols = [col for col in gaze_cols if col in df.columns]\n",
    "            if available_gaze_cols:\n",
    "                data['gaze'] = df[available_gaze_cols].iloc[0].values\n",
    "            \n",
    "            # Extract eye landmarks for gaze visualization\n",
    "            if 'landmarks_2d' in data:\n",
    "                landmarks_2d = data['landmarks_2d']\n",
    "                left_eye_indices = list(range(36, 42))\n",
    "                right_eye_indices = list(range(42, 48))\n",
    "                \n",
    "                data['left_eye'] = landmarks_2d[left_eye_indices]\n",
    "                data['right_eye'] = landmarks_2d[right_eye_indices]\n",
    "            \n",
    "            shutil.rmtree(output_dir, ignore_errors=True)\n",
    "            return data if data else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting landmarks: {e}\")\n",
    "            return None\n",
    "\n",
    "    def check_face_consistency(self, landmarks):\n",
    "        \"\"\"Check face bounding box consistency for debugging\"\"\"\n",
    "        if landmarks is not None and len(landmarks) > 0:\n",
    "            face_width = np.max(landmarks[:,0]) - np.min(landmarks[:,0])\n",
    "            face_height = np.max(landmarks[:,1]) - np.min(landmarks[:,1])\n",
    "            face_center = np.mean(landmarks, axis=0)\n",
    "            \n",
    "            return face_width, face_height, face_center\n",
    "        return None\n",
    "\n",
    "    def draw_openface_3d_cube(self, frame, head_pose, face_center):\n",
    "        \"\"\"Draw 3D head pose cube exactly like OpenFace\"\"\"\n",
    "        if head_pose is None or len(head_pose) != 3:\n",
    "            return frame\n",
    "        \n",
    "        pitch, yaw, roll = head_pose\n",
    "        cube_size = 80\n",
    "        cube_3d = np.array([\n",
    "            [-cube_size, -cube_size, -cube_size], [cube_size, -cube_size, -cube_size],\n",
    "            [cube_size, cube_size, -cube_size], [-cube_size, cube_size, -cube_size],\n",
    "            [-cube_size, -cube_size, cube_size], [cube_size, -cube_size, cube_size],\n",
    "            [cube_size, cube_size, cube_size], [-cube_size, cube_size, cube_size]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Rotation matrices\n",
    "        rx = np.array([[1, 0, 0], [0, np.cos(pitch), -np.sin(pitch)], [0, np.sin(pitch), np.cos(pitch)]])\n",
    "        ry = np.array([[np.cos(yaw), 0, np.sin(yaw)], [0, 1, 0], [-np.sin(yaw), 0, np.cos(yaw)]])\n",
    "        rz = np.array([[np.cos(roll), -np.sin(roll), 0], [np.sin(roll), np.cos(roll), 0], [0, 0, 1]])\n",
    "        \n",
    "        rotation_matrix = rz @ ry @ rx\n",
    "        rotated_cube = cube_3d @ rotation_matrix.T\n",
    "        \n",
    "        # Perspective projection\n",
    "        focal_length = 500\n",
    "        projected_points = []\n",
    "        for point in rotated_cube:\n",
    "            x, y, z = point\n",
    "            x += face_center[0]\n",
    "            y += face_center[1]\n",
    "            z += 200\n",
    "            \n",
    "            if z != 0:\n",
    "                proj_x = int(focal_length * x / z + face_center[0])\n",
    "                proj_y = int(focal_length * y / z + face_center[1])\n",
    "            else:\n",
    "                proj_x = int(x + face_center[0])\n",
    "                proj_y = int(y + face_center[1])\n",
    "            \n",
    "            projected_points.append((proj_x, proj_y))\n",
    "        \n",
    "        projected_points = np.array(projected_points)\n",
    "        \n",
    "        # Draw cube edges\n",
    "        edges = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n",
    "        openface_blue = (255, 128, 0)\n",
    "        \n",
    "        for edge in edges:\n",
    "            pt1 = tuple(projected_points[edge[0]])\n",
    "            pt2 = tuple(projected_points[edge[1]])\n",
    "            \n",
    "            if (0 <= pt1[0] < frame.shape[1] and 0 <= pt1[1] < frame.shape[0] and\n",
    "                0 <= pt2[0] < frame.shape[1] and 0 <= pt2[1] < frame.shape[0]):\n",
    "                cv2.line(frame, pt1, pt2, openface_blue, 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def draw_landmark_deviation_visualization(self, frame, landmarks_2d, landmark_distances):\n",
    "        \"\"\"Draw landmarks with color-coded deviation intensity\"\"\"\n",
    "        if landmarks_2d is None or not landmark_distances:\n",
    "            return frame\n",
    "        \n",
    "        max_distance = max(landmark_distances) if landmark_distances else 1\n",
    "        \n",
    "        for i, (point, distance) in enumerate(zip(landmarks_2d, landmark_distances)):\n",
    "            x, y = int(point[0]), int(point[1])\n",
    "            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:\n",
    "                intensity = min(255, int((distance / max_distance) * 255))\n",
    "                color = (0, 255 - intensity, intensity)\n",
    "                cv2.circle(frame, (x, y), 3, color, -1)\n",
    "                \n",
    "                if distance > max_distance * 0.7:\n",
    "                    cv2.circle(frame, (x, y), 6, (0, 0, 255), 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def draw_openface_landmarks_and_gaze(self, frame, landmarks_2d, left_eye, right_eye, gaze=None):\n",
    "        \"\"\"Draw facial landmarks and gaze exactly like OpenFace\"\"\"\n",
    "        if landmarks_2d is None:\n",
    "            return frame\n",
    "        \n",
    "        if left_eye is not None and right_eye is not None:\n",
    "            left_center = np.mean(left_eye, axis=0).astype(int)\n",
    "            right_center = np.mean(right_eye, axis=0).astype(int)\n",
    "            \n",
    "            eye_radius = 15\n",
    "            cv2.circle(frame, tuple(left_center), eye_radius, (0, 255, 0), 2)\n",
    "            cv2.circle(frame, tuple(right_center), eye_radius, (0, 255, 0), 2)\n",
    "            \n",
    "            if gaze is not None and len(gaze) >= 6:\n",
    "                gaze_scale = 40\n",
    "                left_gaze_end = (int(left_center[0] + gaze[0] * gaze_scale), int(left_center[1] + gaze[1] * gaze_scale))\n",
    "                right_gaze_end = (int(right_center[0] + gaze[3] * gaze_scale), int(right_center[1] + gaze[4] * gaze_scale))\n",
    "                cv2.arrowedLine(frame, tuple(left_center), left_gaze_end, (255, 0, 255), 2)\n",
    "                cv2.arrowedLine(frame, tuple(right_center), right_gaze_end, (255, 0, 255), 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def save_all_data(self, base_filename=None):\n",
    "        \"\"\"Save both CSV data and detailed calculation report to Desktop/Facial Deviation Work folder\"\"\"\n",
    "        if not self.deviation_data:\n",
    "            print(\"No data to save\")\n",
    "            return None, None\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Create \"Facial Deviation Work\" folder on Desktop\n",
    "        home_dir = os.path.expanduser(\"~\")\n",
    "        desktop_path = os.path.join(home_dir, \"Desktop\")\n",
    "        save_directory = os.path.join(desktop_path, \"Facial Deviation Work\")\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(save_directory, exist_ok=True)\n",
    "            test_file = os.path.join(save_directory, \"test_write.tmp\")\n",
    "            with open(test_file, 'w') as f:\n",
    "                f.write(\"test\")\n",
    "            os.remove(test_file)\n",
    "            print(f\"Saving files to: {save_directory}\")\n",
    "        except (OSError, PermissionError) as e:\n",
    "            print(f\"Could not create/access Desktop folder: {e}\")\n",
    "            save_directory = os.path.join(home_dir, \"Facial Deviation Work\")\n",
    "            try:\n",
    "                os.makedirs(save_directory, exist_ok=True)\n",
    "                print(f\"Using fallback directory: {save_directory}\")\n",
    "            except:\n",
    "                print(\"Could not create writable directory for saving files\")\n",
    "                return None, None\n",
    "        \n",
    "        if base_filename is None:\n",
    "            csv_filename = os.path.join(save_directory, f\"facial_rmsd_normalized_{timestamp}.csv\")\n",
    "            report_filename = os.path.join(save_directory, f\"facial_rmsd_normalized_report_{timestamp}.json\")\n",
    "        else:\n",
    "            csv_filename = os.path.join(save_directory, f\"{base_filename}_{timestamp}.csv\")\n",
    "            report_filename = os.path.join(save_directory, f\"{base_filename}_detailed_report_{timestamp}.json\")\n",
    "        \n",
    "        # Save CSV data\n",
    "        try:\n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                if self.deviation_data:\n",
    "                    headers = list(self.deviation_data[0].keys())\n",
    "                    csvfile.write(','.join(headers) + '\\n')\n",
    "                    \n",
    "                    for row in self.deviation_data:\n",
    "                        values = [str(row[key]) for key in headers]\n",
    "                        csvfile.write(','.join(values) + '\\n')\n",
    "                        \n",
    "            print(f\"CSV data saved to: {csv_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save CSV data: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Save detailed report\n",
    "        try:\n",
    "            report_data = {\n",
    "                'session_info': {\n",
    "                    'timestamp': timestamp,\n",
    "                    'total_frames': len(self.deviation_data),\n",
    "                    'total_accumulated_rmsd': float(self.accumulated_rmsd),\n",
    "                    'session_duration': f\"{len(self.deviation_data)} frames\",\n",
    "                    'save_directory': save_directory,\n",
    "                    'normalization_applied': True,\n",
    "                    'rmsd_formula': {\n",
    "                        'description': 'Root Mean Square Deviation from normalized baseline landmarks',\n",
    "                        'formula': 'RMSD = sqrt(Σ(d(pf, pf+a)²) / N)',\n",
    "                        'where': 'd(pf, pf+a) = sqrt((x_pf+a - x_pf)² + (y_pf+a - y_pf)²)',\n",
    "                        'N': '68 facial landmarks',\n",
    "                        'coordinates': 'Normalized to face-relative coordinates (0-1 range)'\n",
    "                    }\n",
    "                },\n",
    "                'summary_statistics': self._calculate_summary_statistics(),\n",
    "                'detailed_frame_calculations': self.detailed_calculations\n",
    "            }\n",
    "            \n",
    "            with open(report_filename, 'w') as jsonfile:\n",
    "                json.dump(report_data, jsonfile, indent=2)\n",
    "                \n",
    "            print(f\"Detailed report saved to: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save detailed report: {e}\")\n",
    "            return csv_filename, None\n",
    "        \n",
    "        self._display_summary_statistics()\n",
    "        return csv_filename, report_filename\n",
    "\n",
    "    def _calculate_summary_statistics(self):\n",
    "        \"\"\"Calculate comprehensive summary statistics\"\"\"\n",
    "        if not self.deviation_data:\n",
    "            return {}\n",
    "        \n",
    "        rmsd_values = []\n",
    "        max_landmark_devs = []\n",
    "        min_landmark_devs = []\n",
    "        std_landmark_devs = []\n",
    "        \n",
    "        for data_point in self.deviation_data:\n",
    "            if 'rmsd_deviation' in data_point:\n",
    "                rmsd_values.append(float(data_point['rmsd_deviation']))\n",
    "            if 'max_landmark_deviation' in data_point:\n",
    "                max_landmark_devs.append(float(data_point['max_landmark_deviation']))\n",
    "            if 'min_landmark_deviation' in data_point:\n",
    "                min_landmark_devs.append(float(data_point['min_landmark_deviation']))\n",
    "            if 'std_landmark_deviation' in data_point:\n",
    "                std_landmark_devs.append(float(data_point['std_landmark_deviation']))\n",
    "        \n",
    "        summary = {\n",
    "            'rmsd_statistics': {\n",
    "                'count': len(rmsd_values),\n",
    "                'mean': float(np.mean(rmsd_values)) if rmsd_values else 0.0,\n",
    "                'median': float(np.median(rmsd_values)) if rmsd_values else 0.0,\n",
    "                'std': float(np.std(rmsd_values)) if rmsd_values else 0.0,\n",
    "                'min': float(np.min(rmsd_values)) if rmsd_values else 0.0,\n",
    "                'max': float(np.max(rmsd_values)) if rmsd_values else 0.0,\n",
    "                'percentiles': {\n",
    "                    '25th': float(np.percentile(rmsd_values, 25)) if rmsd_values else 0.0,\n",
    "                    '75th': float(np.percentile(rmsd_values, 75)) if rmsd_values else 0.0,\n",
    "                    '90th': float(np.percentile(rmsd_values, 90)) if rmsd_values else 0.0,\n",
    "                    '95th': float(np.percentile(rmsd_values, 95)) if rmsd_values else 0.0\n",
    "                }\n",
    "            },\n",
    "            'landmark_deviation_statistics': {\n",
    "                'max_deviations': {\n",
    "                    'mean': float(np.mean(max_landmark_devs)) if max_landmark_devs else 0.0,\n",
    "                    'max': float(np.max(max_landmark_devs)) if max_landmark_devs else 0.0,\n",
    "                    'min': float(np.min(max_landmark_devs)) if max_landmark_devs else 0.0\n",
    "                },\n",
    "                'min_deviations': {\n",
    "                    'mean': float(np.mean(min_landmark_devs)) if min_landmark_devs else 0.0,\n",
    "                    'max': float(np.max(min_landmark_devs)) if min_landmark_devs else 0.0,\n",
    "                    'min': float(np.min(min_landmark_devs)) if min_landmark_devs else 0.0\n",
    "                }\n",
    "            },\n",
    "            'trend_analysis': self._analyze_trends(rmsd_values) if rmsd_values else {},\n",
    "            'high_deviation_analysis': self._analyze_high_deviations(rmsd_values) if rmsd_values else {}\n",
    "        }\n",
    "        return summary\n",
    "\n",
    "    def _analyze_trends(self, rmsd_values):\n",
    "        \"\"\"Analyze trends in RMSD values over time\"\"\"\n",
    "        if len(rmsd_values) < 10:\n",
    "            return {'note': 'Insufficient data for trend analysis (need at least 10 frames)'}\n",
    "        \n",
    "        segment_size = len(rmsd_values) // 3\n",
    "        first_third = rmsd_values[:segment_size]\n",
    "        middle_third = rmsd_values[segment_size:2*segment_size]\n",
    "        last_third = rmsd_values[2*segment_size:]\n",
    "        \n",
    "        first_mean = np.mean(first_third)\n",
    "        middle_mean = np.mean(middle_third)\n",
    "        last_mean = np.mean(last_third)\n",
    "        \n",
    "        if last_mean > first_mean * 1.1:\n",
    "            overall_trend = \"increasing\"\n",
    "        elif last_mean < first_mean * 0.9:\n",
    "            overall_trend = \"decreasing\"\n",
    "        else:\n",
    "            overall_trend = \"stable\"\n",
    "        \n",
    "        return {\n",
    "            'overall_trend': overall_trend,\n",
    "            'first_third_mean': float(first_mean),\n",
    "            'middle_third_mean': float(middle_mean),\n",
    "            'last_third_mean': float(last_mean),\n",
    "            'trend_magnitude': float(abs(last_mean - first_mean)),\n",
    "            'trend_percentage': float(((last_mean - first_mean) / first_mean) * 100) if first_mean > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    def _analyze_high_deviations(self, rmsd_values):\n",
    "        \"\"\"Analyze frames with high deviations\"\"\"\n",
    "        if not rmsd_values:\n",
    "            return {}\n",
    "        \n",
    "        threshold_90 = np.percentile(rmsd_values, 90)\n",
    "        threshold_95 = np.percentile(rmsd_values, 95)\n",
    "        \n",
    "        high_dev_90 = [i for i, val in enumerate(rmsd_values) if val > threshold_90]\n",
    "        high_dev_95 = [i for i, val in enumerate(rmsd_values) if val > threshold_95]\n",
    "        \n",
    "        return {\n",
    "            'threshold_90th_percentile': float(threshold_90),\n",
    "            'threshold_95th_percentile': float(threshold_95),\n",
    "            'frames_above_90th': len(high_dev_90),\n",
    "            'frames_above_95th': len(high_dev_95),\n",
    "            'high_deviation_frame_indices_90th': high_dev_90[:10],\n",
    "            'high_deviation_frame_indices_95th': high_dev_95[:10],\n",
    "            'percentage_high_deviation_frames': float((len(high_dev_90) / len(rmsd_values)) * 100)\n",
    "        }\n",
    "\n",
    "    def _display_summary_statistics(self):\n",
    "        \"\"\"Display summary statistics in console\"\"\"\n",
    "        if not self.deviation_data:\n",
    "            print(\"No data available for summary\")\n",
    "            return\n",
    "        \n",
    "        summary = self._calculate_summary_statistics()\n",
    "        \n",
    "        print(\"\\n NORMALIZED RMSD ANALYSIS SUMMARY:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        rmsd_stats = summary.get('rmsd_statistics', {})\n",
    "        if rmsd_stats:\n",
    "            print(f\" RMSD Statistics ({rmsd_stats['count']} frames):\")\n",
    "            print(f\"  • Mean RMSD: {rmsd_stats['mean']:.8f}\")\n",
    "            print(f\"  • Median RMSD: {rmsd_stats['median']:.8f}\")\n",
    "            print(f\"  • Standard Deviation: {rmsd_stats['std']:.8f}\")\n",
    "            print(f\"  • Range: {rmsd_stats['min']:.8f} - {rmsd_stats['max']:.8f}\")\n",
    "            print(f\"  • 90th Percentile: {rmsd_stats['percentiles']['90th']:.8f}\")\n",
    "            print(f\"  • 95th Percentile: {rmsd_stats['percentiles']['95th']:.8f}\")\n",
    "        \n",
    "        trend_analysis = summary.get('trend_analysis', {})\n",
    "        if trend_analysis and 'overall_trend' in trend_analysis:\n",
    "            print(f\"\\n Trend Analysis:\")\n",
    "            print(f\"  • Overall trend: {trend_analysis['overall_trend']}\")\n",
    "            print(f\"  • Trend magnitude: {trend_analysis['trend_magnitude']:.8f}\")\n",
    "            print(f\"  • Percentage change: {trend_analysis['trend_percentage']:.2f}%\")\n",
    "        \n",
    "        high_dev = summary.get('high_deviation_analysis', {})\n",
    "        if high_dev:\n",
    "            print(f\"\\n High Deviation Analysis:\")\n",
    "            print(f\"  • Frames above 90th percentile: {high_dev['frames_above_90th']}\")\n",
    "            print(f\"  • Frames above 95th percentile: {high_dev['frames_above_95th']}\")\n",
    "            print(f\"  • Percentage of high deviation frames: {high_dev['percentage_high_deviation_frames']:.2f}%\")\n",
    "        \n",
    "        print(\"\\n Key Improvements in This Version:\")\n",
    "        print(\"  • COORDINATE NORMALIZATION - Fixed position/scale issues\")\n",
    "        print(\"  • Realistic RMSD values (0.001-0.1 range)\")\n",
    "        print(\"  • Face-relative landmark comparison\")\n",
    "        print(\"  • Enhanced debugging with normalized coordinates\")\n",
    "\n",
    "    def analyze_deviation_patterns(self):\n",
    "        \"\"\"Analyze deviation patterns and provide insights\"\"\"\n",
    "        if not self.deviation_data:\n",
    "            print(\"No data available for analysis\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n NORMALIZED RMSD Deviation Pattern Analysis:\")\n",
    "        \n",
    "        summary = self._calculate_summary_statistics()\n",
    "        rmsd_stats = summary.get('rmsd_statistics', {})\n",
    "        \n",
    "        if rmsd_stats:\n",
    "            print(f\"  • Average RMSD: {rmsd_stats['mean']:.8f}\")\n",
    "            print(f\"  • RMSD Range: {rmsd_stats['min']:.8f} - {rmsd_stats['max']:.8f}\")\n",
    "            print(f\"  • RMSD Standard Deviation: {rmsd_stats['std']:.8f}\")\n",
    "            \n",
    "            trend_analysis = summary.get('trend_analysis', {})\n",
    "            if trend_analysis and 'overall_trend' in trend_analysis:\n",
    "                print(f\"  • Overall trend: {trend_analysis['overall_trend']}\")\n",
    "                print(f\"  • Trend change: {trend_analysis['trend_percentage']:.2f}%\")\n",
    "            \n",
    "            high_dev = summary.get('high_deviation_analysis', {})\n",
    "            if high_dev:\n",
    "                print(f\"  • High deviation frames (top 10%): {high_dev['frames_above_90th']} frames\")\n",
    "                print(f\"  • Extreme deviation frames (top 5%): {high_dev['frames_above_95th']} frames\")\n",
    "        else:\n",
    "            print(\"  • Error: Could not calculate statistics\")\n",
    "            print(f\"  • Raw data points: {len(self.deviation_data)}\")\n",
    "            print(f\"  • Accumulated RMSD: {self.accumulated_rmsd:.8f}\")\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up temporary files\"\"\"\n",
    "        if hasattr(self, 'temp_dir') and os.path.exists(self.temp_dir):\n",
    "            shutil.rmtree(self.temp_dir, ignore_errors=True)\n",
    "            print(f\"Cleaned up temporary directory: {self.temp_dir}\")\n",
    "        else:\n",
    "            print(\"No temporary directory to clean up\")\n",
    "\n",
    "# Usage Example with Enhanced Debugging\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = None\n",
    "    report_file = None\n",
    "    \n",
    "    try:\n",
    "        print(\"=== INITIALIZATION ===\")\n",
    "        tracker = RealTimeFacialDeviationTracker()\n",
    "        \n",
    "        print(\"=== DIAGNOSTIC CHECKS ===\")\n",
    "        import os\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        print(f\"Home directory: {os.path.expanduser('~')}\")\n",
    "        desktop_work_dir = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"Facial Deviation Work\")\n",
    "        try:\n",
    "            os.makedirs(desktop_work_dir, exist_ok=True)\n",
    "            print(f\"Successfully created/verified: {desktop_work_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot create Desktop folder: {e}\")\n",
    "        \n",
    "        print(\"\\n=== STEP 1: BASELINE SETUP ===\")\n",
    "        if tracker.setup_baseline(num_frames=20):\n",
    "            print(\"Baseline established successfully!\")\n",
    "            \n",
    "            print(\"\\n=== STEP 2: REAL-TIME TRACKING ===\")\n",
    "            print(\"DEBUG MODE: Will show detailed diagnostics for first few frames\")\n",
    "            csv_file, report_file = tracker.start_tracking(jupyter_mode=True)\n",
    "            \n",
    "            if csv_file and report_file:\n",
    "                print(f\"\\nSession complete!\")\n",
    "                print(f\"CSV Data: {csv_file}\")\n",
    "                print(f\"Detailed Report: {report_file}\")\n",
    "                \n",
    "                print(\"\\n=== STEP 3: PATTERN ANALYSIS ===\")\n",
    "                tracker.analyze_deviation_patterns()\n",
    "                \n",
    "                print(f\"\\nFiles Created:\")\n",
    "                print(f\"  1. {csv_file} - Raw RMSD data\")\n",
    "                print(f\"  2. {report_file} - Detailed calculations and diagnostics\")\n",
    "            else:\n",
    "                print(\"Error occurred during data saving\")\n",
    "        else:\n",
    "            print(\"Failed to establish baseline\")\n",
    "            print(\"Tips:\")\n",
    "            print(\"  • Ensure good lighting\")\n",
    "            print(\"  • Face the camera directly\")\n",
    "            print(\"  • Keep head still during baseline\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted by user\")\n",
    "        if 'tracker' in locals() and tracker.deviation_data:\n",
    "            print(\"Attempting to save partial data...\")\n",
    "            csv_file, report_file = tracker.save_all_data()\n",
    "            if csv_file:\n",
    "                print(f\"Partial data saved: {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if 'tracker' in locals():\n",
    "            tracker.cleanup()\n",
    "        print(\"Session ended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empathy_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
